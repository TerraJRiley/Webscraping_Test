{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports for all notebooks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scraping Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "from random import randint\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "# Specific Imports as a result of ChatGPT's Suggested Code Functions\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_with_retry(driver, css_selector, max_attempts=5, wait_time=10, extra_scroll=150):\n",
    "    \"\"\"\n",
    "    Tries to find and click an element specified by the CSS selector.\n",
    "    Waits for the element to be visible and clickable.\n",
    "    Retries up to max_attempts times if StaleElementReferenceException is encountered.\n",
    "\n",
    "    :param driver: The Selenium WebDriver.\n",
    "    :param css_selector: CSS selector of the element to be clicked.\n",
    "    :param max_attempts: Maximum number of attempts to try clicking the element.\n",
    "    :param wait_time: Time to wait for the element to become visible and clickable.\n",
    "    :return: True if click was successful, False if it failed after max_attempts.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Wait for the element to be visible\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Scroll the element into view with extra space\n",
    "            driver.execute_script(\"window.scroll(0, arguments[0].getBoundingClientRect().top + window.pageYOffset - arguments[1]);\", element, extra_scroll)\n",
    "\n",
    "            # Wait for the element to be clickable\n",
    "            WebDriverWait(driver, wait_time).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Click the element\n",
    "            element.click()\n",
    "            return True\n",
    "\n",
    "        except (StaleElementReferenceException, TimeoutException):\n",
    "            pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_with_retry(driver, css_selector, max_attempts=5, wait_time=10, extra_scroll=150):\n",
    "    \"\"\"\n",
    "    Tries to find an element specified by the CSS selector and get its text.\n",
    "    Waits for the element to be visible.\n",
    "    Retries up to max_attempts times if StaleElementReferenceException is encountered.\n",
    "\n",
    "    :param driver: The Selenium WebDriver.\n",
    "    :param css_selector: CSS selector of the element.\n",
    "    :param max_attempts: Maximum number of attempts to try getting the text.\n",
    "    :param wait_time: Time to wait for the element to become visible.\n",
    "    :return: The text of the element if successful, None if it failed after max_attempts.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Wait for the element to be visible\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Scroll the element into view with extra space\n",
    "            driver.execute_script(\n",
    "                \"window.scroll(0, arguments[0].getBoundingClientRect().top + window.pageYOffset - arguments[1]);\", \n",
    "                element, extra_scroll)\n",
    "\n",
    "            # Return the text of the element\n",
    "            return element.text\n",
    "\n",
    "        except (StaleElementReferenceException, NoSuchElementException, TimeoutException):\n",
    "            pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Selenium Window\n",
    "fun_options = Options()\n",
    "fun_driver = webdriver.Firefox(options=fun_options)\n",
    "fun_driver.get(\"https://www.facebook.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peridot of Earth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other_Number</th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Name_First</th>\n",
       "      <th>Name_Last</th>\n",
       "      <th>Gender</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12102965600</td>\n",
       "      <td>596897507</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Murphy</td>\n",
       "      <td>female</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>Married</td>\n",
       "      <td>Stay-at-home mom</td>\n",
       "      <td>12/5/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12102965601</td>\n",
       "      <td>100028359581007</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Ortiz</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/0001 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12102965607</td>\n",
       "      <td>1456394131</td>\n",
       "      <td>Alida</td>\n",
       "      <td>Canion</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USAA</td>\n",
       "      <td>12/7/2015 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102965613</td>\n",
       "      <td>100016005185942</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Duerr</td>\n",
       "      <td>male</td>\n",
       "      <td>Somerset, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAA</td>\n",
       "      <td>11/29/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12102965614</td>\n",
       "      <td>100009325868432</td>\n",
       "      <td>George</td>\n",
       "      <td>Gomez</td>\n",
       "      <td>male</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/19/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Other_Number          Url_Key Name_First Name_Last  Gender  \\\n",
       "0  12102965600        596897507      Sarah    Murphy  female   \n",
       "1  12102965601  100028359581007     Victor     Ortiz    male   \n",
       "2  12102965607       1456394131      Alida    Canion  female   \n",
       "3  12102965613  100016005185942     Austin     Duerr    male   \n",
       "4  12102965614  100009325868432     George     Gomez    male   \n",
       "\n",
       "                    1                   2        3                 4  \\\n",
       "0  San Antonio, Texas  San Antonio, Texas  Married  Stay-at-home mom   \n",
       "1                 NaN                 NaN      NaN               NaN   \n",
       "2                 NaN                 NaN      NaN              USAA   \n",
       "3     Somerset, Texas  San Antonio, Texas      NaN               AAA   \n",
       "4  San Antonio, Texas  San Antonio, Texas   Single               NaN   \n",
       "\n",
       "               5    6      7    8    9  \n",
       "0   12/5/2018 12  0.0  00 AM  NaN  NaN  \n",
       "1    1/1/0001 12  0.0  00 AM  NaN  NaN  \n",
       "2   12/7/2015 12  0.0  00 AM  NaN  NaN  \n",
       "3  11/29/2018 12  0.0  00 AM  NaN  NaN  \n",
       "4  11/19/2018 12  0.0  00 AM  NaN  NaN  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"./data/sample_edited.txt\", sep=\":\", header=None, \n",
    "                        names=[\"Other_Number\", \"Url_Key\", \"Name_First\", \"Name_Last\", \"Gender\",\n",
    "                               \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "#df_sample = pd.DataFrame(data)\n",
    "df_sample['Url_Key'] = df_sample['Url_Key'].astype(str)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>...</th>\n",
       "      <th>Details About Betty</th>\n",
       "      <th>Details About Jorge Alan</th>\n",
       "      <th>Details About Claudia</th>\n",
       "      <th>Details About Morris</th>\n",
       "      <th>Details About Linda</th>\n",
       "      <th>Details About Nadia</th>\n",
       "      <th>Details About Ignacio</th>\n",
       "      <th>Details About Iris</th>\n",
       "      <th>Details About Victor</th>\n",
       "      <th>Details About Sylvia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>100005286972887</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...</td>\n",
       "      <td>Iris NTony Barrera</td>\n",
       "      <td>926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Teacher at Edgewood ISD - San Antonio, Texas\\n...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relationship\\nMarried since March 8, 2008\\nFam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1024645391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrape Failed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>100013396143349</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t1.6435...</td>\n",
       "      <td>Victor McCord</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Worked at VA Medical Center-Temple,TX</td>\n",
       "      <td>Studied at Sam Houston State University</td>\n",
       "      <td>Went to Richard King High School</td>\n",
       "      <td>Lived in Temple, Texas</td>\n",
       "      <td>From Corpus Christi, Texas</td>\n",
       "      <td>Worked at VA Medical Center-Temple,TX\\nJune 18...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Victor\\nNo additional details to show\\nN...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>100015290598679</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t1.1816...</td>\n",
       "      <td>Sylvia Casarez-Valle</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No workplaces to show\\nNo schools to show\\nNo ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relationship\\nNo relationship info to show\\nFa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1383668282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrape Failed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Url_Key                               Profile Picture Link  \\\n",
       "105  100005286972887  https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...   \n",
       "106       1024645391                                                NaN   \n",
       "107  100013396143349  https://scontent-sjc3-1.xx.fbcdn.net/v/t1.6435...   \n",
       "108  100015290598679  https://scontent-sjc3-1.xx.fbcdn.net/v/t1.1816...   \n",
       "109       1383668282                                                NaN   \n",
       "\n",
       "                      Name  Num_Friends  \\\n",
       "105    Iris NTony Barrera         926.0   \n",
       "106          Scrape Failed          NaN   \n",
       "107         Victor McCord         186.0   \n",
       "108  Sylvia Casarez-Valle          96.0   \n",
       "109          Scrape Failed          NaN   \n",
       "\n",
       "                                   Intro 1  \\\n",
       "105                                    NaN   \n",
       "106                                    NaN   \n",
       "107  Worked at VA Medical Center-Temple,TX   \n",
       "108                                    NaN   \n",
       "109                                    NaN   \n",
       "\n",
       "                                     Intro 2  \\\n",
       "105                                      NaN   \n",
       "106                                      NaN   \n",
       "107  Studied at Sam Houston State University   \n",
       "108                                      NaN   \n",
       "109                                      NaN   \n",
       "\n",
       "                              Intro 3                 Intro 4  \\\n",
       "105                               NaN                     NaN   \n",
       "106                               NaN                     NaN   \n",
       "107  Went to Richard King High School  Lived in Temple, Texas   \n",
       "108                               NaN                     NaN   \n",
       "109                               NaN                     NaN   \n",
       "\n",
       "                        Intro 5  \\\n",
       "105                         NaN   \n",
       "106                         NaN   \n",
       "107  From Corpus Christi, Texas   \n",
       "108                         NaN   \n",
       "109                         NaN   \n",
       "\n",
       "                                      Overview (About)  ...  \\\n",
       "105  Teacher at Edgewood ISD - San Antonio, Texas\\n...  ...   \n",
       "106                                                NaN  ...   \n",
       "107  Worked at VA Medical Center-Temple,TX\\nJune 18...  ...   \n",
       "108  No workplaces to show\\nNo schools to show\\nNo ...  ...   \n",
       "109                                                NaN  ...   \n",
       "\n",
       "    Details About Betty Details About Jorge Alan Details About Claudia  \\\n",
       "105                 NaN                      NaN                   NaN   \n",
       "106                 NaN                      NaN                   NaN   \n",
       "107                 NaN                      NaN                   NaN   \n",
       "108                 NaN                      NaN                   NaN   \n",
       "109                 NaN                      NaN                   NaN   \n",
       "\n",
       "    Details About Morris Details About Linda Details About Nadia  \\\n",
       "105                  NaN                 NaN                 NaN   \n",
       "106                  NaN                 NaN                 NaN   \n",
       "107                  NaN                 NaN                 NaN   \n",
       "108                  NaN                 NaN                 NaN   \n",
       "109                  NaN                 NaN                 NaN   \n",
       "\n",
       "    Details About Ignacio                                 Details About Iris  \\\n",
       "105                   NaN  Relationship\\nMarried since March 8, 2008\\nFam...   \n",
       "106                   NaN                                                NaN   \n",
       "107                   NaN                                                NaN   \n",
       "108                   NaN                                                NaN   \n",
       "109                   NaN                                                NaN   \n",
       "\n",
       "                                  Details About Victor  \\\n",
       "105                                                NaN   \n",
       "106                                                NaN   \n",
       "107  About Victor\\nNo additional details to show\\nN...   \n",
       "108                                                NaN   \n",
       "109                                                NaN   \n",
       "\n",
       "                                  Details About Sylvia  \n",
       "105                                                NaN  \n",
       "106                                                NaN  \n",
       "107                                                NaN  \n",
       "108  Relationship\\nNo relationship info to show\\nFa...  \n",
       "109                                                NaN  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped = pd.read_csv(\"./data/scraped_data.csv\")\n",
    "df_scraped.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL key 596897507 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100028359581007 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1456394131 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100016005185942 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100009325868432 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000816665642 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1332364398 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001903893043 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1176820391 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1492133068 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100007398875957 already exists in df_scraped, skipping data gathering.\n",
      "URL key 620962824 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012369630553 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002472819691 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100006173103626 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1534680025 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002157457935 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100004076081283 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1614400498 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003014471974 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015110614808 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100007334431871 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1439300531 already exists in df_scraped, skipping data gathering.\n",
      "URL key 530564022 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001470542942 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002147105590 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001322273594 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100030011204103 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100016689155244 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015501282735 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002523411969 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1536324458 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000685680938 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100006299070220 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015315091942 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100029243739700 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000558933956 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100024863707960 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100014771977207 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012552762940 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100023403651326 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100014276734566 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1624317525 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012944562242 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1348957581 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012905439141 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1079942548 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100028014167086 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001299159082 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100010679745179 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100025067146823 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100029077760565 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1541220075 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1116227316 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001738218938 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100023890207507 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008097431302 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000100276241 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001099482459 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1034922575 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001270794925 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1422612112 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002960830326 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100022957322696 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002470216513 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012172716077 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003030198755 already exists in df_scraped, skipping data gathering.\n",
      "URL key 2341374 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1785348257 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100005729760913 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008641711591 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001354347525 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100033028149864 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000396210621 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100005502373291 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002241216969 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100025990270303 already exists in df_scraped, skipping data gathering.\n",
      "URL key 746050153 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003716670077 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1507153635 already exists in df_scraped, skipping data gathering.\n",
      "URL key 35700068 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1312288002 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001554841889 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100023671986994 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100004499142779 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012911462816 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008231524112 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1705977842 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001561901269 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002507628728 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1586867440 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002440081467 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100022819035571 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012641199103 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1542783703 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100023660828232 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100010255891645 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100005286972887 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1615329336 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001877117536 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100026736272330 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100027109280979 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100025770104440 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100022509513829 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100010086284813 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100028544986930 already exists in df_scraped, skipping data gathering.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL key 100001200819096 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100009196077406 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1024645391 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100013396143349 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015290598679 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1383668282 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100007970589604 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002453679261 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012575792921 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1634243144 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100019644214521 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100024449658884 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1336047083 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100005917021063 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000940061973 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003818216557 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1455827653 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000052942781 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100027803708722 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100007313265431 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100004562581521 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100012182862892 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000798524469 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100022148653570 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008017694463 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000564815201 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008764963900 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1606582274 already exists in df_scraped, skipping data gathering.\n",
      "URL key 533211958 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001723306438 already exists in df_scraped, skipping data gathering.\n",
      "URL key 636744001 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100002095456665 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1178910658 already exists in df_scraped, skipping data gathering.\n",
      "URL key 25408852 already exists in df_scraped, skipping data gathering.\n",
      "URL key 567454691 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100011643540675 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003097279252 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015394441793 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100031523730943 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000136777609 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1131781499 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100003263270050 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000512148257 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100014000177890 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100000235422831 already exists in df_scraped, skipping data gathering.\n",
      "URL key 582043614 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100014065844556 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100007395375097 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1463173970 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001204938973 already exists in df_scraped, skipping data gathering.\n",
      "URL key 521155837 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001723015746 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100008011037433 already exists in df_scraped, skipping data gathering.\n",
      "URL key 719728778 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100006682264051 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100028221740736 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001341744490 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1094958832 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100005782031190 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100023242032599 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100001029984156 already exists in df_scraped, skipping data gathering.\n"
     ]
    }
   ],
   "source": [
    "for Url_Key in df_sample['Url_Key']:\n",
    "    sleep(0.5 + randint(10,9999999)/10000000)\n",
    "    # Check if Url_Key is not in df_scraped\n",
    "    df_scraped = pd.read_csv(\"./data/scraped_data.csv\")\n",
    "    df_scraped['Url_Key'] = df_scraped['Url_Key'].astype(str)\n",
    "    Url_Key = str(Url_Key)\n",
    "    if Url_Key not in df_scraped['Url_Key'].values:\n",
    "        \n",
    "        # Calling Dibs on this profile\n",
    "        dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scraper 1 has dibs!\"}\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"./data/scraped_data.csv\", index = False)\n",
    "        \n",
    "        \n",
    "        fun_driver.get(\"https://www.facebook.com/\" + Url_Key)\n",
    "        # Gather data using Url_Key\n",
    "        dict_person = {\"Url_Key\" : Url_Key}\n",
    "        try:\n",
    "            # Obtain Profile Picture\n",
    "            dict_person[\"Profile Picture Link\"] = fun_driver.find_element(by=\"css selector\", \n",
    "                value = \"a.xzsf02u > div:nth-child(1) > svg:nth-child(1) > g:nth-child(2) > image:nth-child(1)\"\n",
    "                ).get_attribute(\"xlink:href\")\n",
    "\n",
    "            # Obtain Name\n",
    "            dict_person[\"Name\"] = get_text_with_retry(fun_driver, \".x14qwyeo > h1:nth-child(1)\")\n",
    "\n",
    "            # Obtain Number of Friends\n",
    "            dict_person[\"Num_Friends\"] = int(get_text_with_retry(fun_driver, \"a.xi81zsa\").split(\" \")[0])\n",
    "\n",
    "            # Obtain Intro Lines\n",
    "            html_current = BeautifulSoup(fun_driver.page_source, \"lxml\")\n",
    "            list_intro_el = html_current.select(\n",
    "                \"div.x7wzq59:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "                + \" div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "                + \" ul:nth-child(1) > div\")\n",
    "            for num in range(len(list_intro_el)):\n",
    "                dict_person[\"Intro \" + str(num + 1)] = list_intro_el[num].text\n",
    "                #print(list_intro_el[num].text)\n",
    "\n",
    "\n",
    "            # Click About Tab\n",
    "            click_with_retry(fun_driver, \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\")\n",
    "            #Get Overview Section First\n",
    "            dict_person[\"Overview (About)\"] = get_text_with_retry(fun_driver, \".xqmdsaz\")\n",
    "            \n",
    "            # Obtain About Section\n",
    "            for num in range(3, 9):\n",
    "                css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "                click_with_retry(fun_driver, css_selector_to_click)\n",
    "                el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "                el_temp_text = el_temp.text\n",
    "                css_path_content = \".xqmdsaz\"\n",
    "                content_text = get_text_with_retry(fun_driver, css_path_content)\n",
    "                if content_text is not None:\n",
    "                    dict_person[el_temp_text] = content_text\n",
    "                    #print(\"element's text hath been saved!\")\n",
    "                else:\n",
    "                    print(\"Failed to retrieve text for element:\", el_temp_text)\n",
    "        except:\n",
    "            dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scrape Failed\"}\n",
    "        \n",
    "        \n",
    "        # Append the new data to df_scraped\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"./data/scraped_data.csv\", index = False)\n",
    "    \n",
    "    else:\n",
    "        # Skip the data gathering process\n",
    "        print(f\"URL key {Url_Key} already exists in df_scraped, skipping data gathering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Test Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Key = \"596897507\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_driver.get(\"https://www.facebook.com/\" + Url_Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_person = {}\n",
    "# Need to obtain the following:\n",
    "# Profile Picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_person[\"Url_Key\"] = Url_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Profile Picture\n",
    "dict_person[\"Profile Picture Link\"] = fun_driver.find_element(by=\"css selector\", \n",
    "    value = \"a.xzsf02u > div:nth-child(1) > svg:nth-child(1) > g:nth-child(2) > image:nth-child(1)\"\n",
    "    ).get_attribute(\"xlink:href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Name\n",
    "dict_person[\"Name\"] = get_text_with_retry(fun_driver, \".x14qwyeo > h1:nth-child(1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Number of Friends\n",
    "dict_person[\"Num_Friends\"] = int(get_text_with_retry(fun_driver, \"a.xi81zsa\").split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went to Ashland High School\n",
      "Lives in San Antonio, Texas\n",
      "From San Antonio, Texas\n",
      "Married to Matt Murphy\n",
      "Joined October 2007\n"
     ]
    }
   ],
   "source": [
    "# Obtain Intro Lines\n",
    "html_current = BeautifulSoup(fun_driver.page_source, \"lxml\")\n",
    "\n",
    "list_intro_el = html_current.select(\n",
    "    \"div.x7wzq59:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "    + \" div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "    + \" ul:nth-child(1) > div\")\n",
    "\n",
    "for num in range(len(list_intro_el)):\n",
    "    dict_person[\"Intro \" + str(num + 1)] = list_intro_el[num].text\n",
    "    print(list_intro_el[num].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click About Tab\n",
    "click_with_retry(fun_driver, \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\")\n",
    "\n",
    "#Get Overview Section First\n",
    "dict_person[\"Overview (About)\"] = get_text_with_retry(fun_driver, \".xqmdsaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "temp el: Work and education clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Places lived clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Contact and basic info clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Family and relationships clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Details About Sarah clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Life events clicked\n",
      "element's text hath been saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtain About Section\n",
    "for num in range(3, 9):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # CSS selector for the current element to click\n",
    "    css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    \n",
    "    # Clicking the next About Sub-Section\n",
    "    click_with_retry(fun_driver, css_selector_to_click)\n",
    "    \n",
    "    # Re-find the element to avoid stale reference\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "    el_temp_text = el_temp.text\n",
    "    print(\"temp el: \" + el_temp_text + \" clicked\")\n",
    "    \n",
    "    # Consuming its informational content\n",
    "    css_path_content = \".xqmdsaz\"\n",
    "    content_text = get_text_with_retry(fun_driver, css_path_content)\n",
    "    if content_text is not None:\n",
    "        dict_person[el_temp_text] = content_text\n",
    "        print(\"element's text hath been saved!\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve text for element:\", el_temp_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>Work and education</th>\n",
       "      <th>Places lived</th>\n",
       "      <th>Contact and basic info</th>\n",
       "      <th>Family and relationships</th>\n",
       "      <th>Details About Sarah</th>\n",
       "      <th>Life events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596897507</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...</td>\n",
       "      <td>Sarah Murphy</td>\n",
       "      <td>444</td>\n",
       "      <td>Went to Ashland High School</td>\n",
       "      <td>Lives in San Antonio, Texas</td>\n",
       "      <td>From San Antonio, Texas</td>\n",
       "      <td>Married to Matt Murphy</td>\n",
       "      <td>Joined October 2007</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>Work\\nNo workplaces to show\\nCollege\\nNo schoo...</td>\n",
       "      <td>Places lived\\nSan Antonio, Texas\\nCurrent city...</td>\n",
       "      <td>Contact info\\nNo contact info to show\\nWebsite...</td>\n",
       "      <td>Relationship\\nMatt Murphy\\nMarried to Matt Mur...</td>\n",
       "      <td>2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Url_Key                               Profile Picture Link  \\\n",
       "0  596897507  https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...   \n",
       "\n",
       "            Name  Num_Friends                      Intro 1  \\\n",
       "0  Sarah Murphy           444  Went to Ashland High School   \n",
       "\n",
       "                       Intro 2                  Intro 3  \\\n",
       "0  Lives in San Antonio, Texas  From San Antonio, Texas   \n",
       "\n",
       "                  Intro 4              Intro 5  \\\n",
       "0  Married to Matt Murphy  Joined October 2007   \n",
       "\n",
       "                                    Overview (About)  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                  Work and education  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                        Places lived  \\\n",
       "0  Work\\nNo workplaces to show\\nCollege\\nNo schoo...   \n",
       "\n",
       "                              Contact and basic info  \\\n",
       "0  Places lived\\nSan Antonio, Texas\\nCurrent city...   \n",
       "\n",
       "                            Family and relationships  \\\n",
       "0  Contact info\\nNo contact info to show\\nWebsite...   \n",
       "\n",
       "                                 Details About Sarah  \\\n",
       "0  Relationship\\nMatt Murphy\\nMarried to Matt Mur...   \n",
       "\n",
       "                                         Life events  \n",
       "0  2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped = pd.DataFrame(dict_person, index=[0])\n",
    "df_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.to_csv(\"./data/scraped_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>Work and education</th>\n",
       "      <th>Places lived</th>\n",
       "      <th>Contact and basic info</th>\n",
       "      <th>Family and relationships</th>\n",
       "      <th>Details About Sarah</th>\n",
       "      <th>Life events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596897507</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...</td>\n",
       "      <td>Sarah Murphy</td>\n",
       "      <td>444</td>\n",
       "      <td>Went to Ashland High School</td>\n",
       "      <td>Lives in San Antonio, Texas</td>\n",
       "      <td>From San Antonio, Texas</td>\n",
       "      <td>Married to Matt Murphy</td>\n",
       "      <td>Joined October 2007</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>Work\\nNo workplaces to show\\nCollege\\nNo schoo...</td>\n",
       "      <td>Places lived\\nSan Antonio, Texas\\nCurrent city...</td>\n",
       "      <td>Contact info\\nNo contact info to show\\nWebsite...</td>\n",
       "      <td>Relationship\\nMatt Murphy\\nMarried to Matt Mur...</td>\n",
       "      <td>2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Url_Key                               Profile Picture Link  \\\n",
       "0  596897507  https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...   \n",
       "\n",
       "            Name  Num_Friends                      Intro 1  \\\n",
       "0  Sarah Murphy           444  Went to Ashland High School   \n",
       "\n",
       "                       Intro 2                  Intro 3  \\\n",
       "0  Lives in San Antonio, Texas  From San Antonio, Texas   \n",
       "\n",
       "                  Intro 4              Intro 5  \\\n",
       "0  Married to Matt Murphy  Joined October 2007   \n",
       "\n",
       "                                    Overview (About)  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                  Work and education  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                        Places lived  \\\n",
       "0  Work\\nNo workplaces to show\\nCollege\\nNo schoo...   \n",
       "\n",
       "                              Contact and basic info  \\\n",
       "0  Places lived\\nSan Antonio, Texas\\nCurrent city...   \n",
       "\n",
       "                            Family and relationships  \\\n",
       "0  Contact info\\nNo contact info to show\\nWebsite...   \n",
       "\n",
       "                                 Details About Sarah  \\\n",
       "0  Relationship\\nMatt Murphy\\nMarried to Matt Mur...   \n",
       "\n",
       "                                         Life events  \n",
       "0  2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./data/scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fun_extended_wait(css_selector, driver):\n",
    "    locator = (By.CSS_SELECTOR, css_selector)\n",
    "    try:\n",
    "        # Wait for the element to be available and interact with it\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))\n",
    "        # Perform actions with element\n",
    "    except StaleElementReferenceException:\n",
    "        # Element is stale, re-find or handle the exception\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))\n",
    "        # Perform actions with refreshed element\n",
    "    sleep(1 + randint(10,9999999)/10000000)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for num in range(3,8):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # Clicking next About Sub-Section\n",
    "    css_path = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    fun_extended_wait(css_path, fun_driver)\n",
    "    sleep(3 + randint(10,9999999)/10000000)\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value = css_path)\n",
    "    el_temp.click()\n",
    "    print(\"temp el: \" + el_temp.text + \" clicked\")\n",
    "    \n",
    "    # Consuming it's informational meat\n",
    "    css_path = \".xqmdsaz\"\n",
    "    fun_extended_wait(css_path, fun_driver)\n",
    "    dict_person[el_temp.text] = fun_driver.find_element(by=\"css selector\", value = css_path).text\n",
    "    print(\"element's text hath been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path)\n",
    "\n",
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=\" + str(alt_user_name))\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path, options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for num in range(3,8):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # CSS selector for the current element to click\n",
    "    css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    \n",
    "    # Clicking the next About Sub-Section\n",
    "    click_with_retry(fun_driver, css_selector_to_click)\n",
    "    \n",
    "    # Re-find the element to avoid stale reference\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "    print(\"temp el: \" + el_temp.text + \" clicked\")\n",
    "    \n",
    "    # Consuming it's informational meat\n",
    "    css_path = \".xqmdsaz\"\n",
    "    #fun_extended_wait(css_path, fun_driver)\n",
    "    dict_person[el_temp.text] = fun_driver.find_element(by=\"css selector\", value = css_path).text\n",
    "    print(\"element's text hath been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\",\n",
    "                        value = \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_overview = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Overview (About)\"] = about_overview\n",
    "about_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #2 Work & Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(3) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_workanded = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Work & Education (About)\"] = about_workanded\n",
    "about_workanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #3 Places Lived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(4) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_placeslived = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Places Lived (About)\"] = about_placeslived\n",
    "about_placeslived\n",
    "# Should be placed into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #4 Contact and basic info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(5) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_contact = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Contact and basic info (About)\"] = about_contact\n",
    "about_contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #5 Family and Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(6) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_family = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Family & Relationships (About)\"] = about_family\n",
    "about_family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #6 Details About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(7) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_details = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Details About Profile (About)\"] = about_details\n",
    "about_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #7 Life Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(8) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_overview = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Overview (About)\"] = about_overview\n",
    "about_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Calling Dibs on this profile\n",
    "        dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scraper # has dibs!\"}\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"./data/scraped_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_lifeEvents = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Life Events (About)\"] = about_lifeEvents\n",
    "about_lifeEvents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
