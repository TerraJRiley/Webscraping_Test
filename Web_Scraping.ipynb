{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports for all notebooks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scraping Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "import re\n",
    "from random import randint\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "# Specific Imports as a result of ChatGPT's Suggested Code Functions\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_with_retry(driver, css_selector, max_attempts=5, wait_time=5, extra_scroll=150):\n",
    "    \"\"\"\n",
    "    Tries to find and click an element specified by the CSS selector.\n",
    "    Waits for the element to be visible and clickable.\n",
    "    Retries up to max_attempts times if StaleElementReferenceException is encountered.\n",
    "\n",
    "    :param driver: The Selenium WebDriver.\n",
    "    :param css_selector: CSS selector of the element to be clicked.\n",
    "    :param max_attempts: Maximum number of attempts to try clicking the element.\n",
    "    :param wait_time: Time to wait for the element to become visible and clickable.\n",
    "    :return: True if click was successful, False if it failed after max_attempts.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Wait for the element to be visible\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Scroll the element into view with extra space\n",
    "            driver.execute_script(\"window.scroll(0, arguments[0].getBoundingClientRect().top + window.pageYOffset - arguments[1]);\", element, extra_scroll)\n",
    "\n",
    "            # Wait for the element to be clickable\n",
    "            WebDriverWait(driver, wait_time).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Click the element\n",
    "            element.click()\n",
    "            return True\n",
    "\n",
    "        except (StaleElementReferenceException, TimeoutException):\n",
    "            pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_with_retry(driver, css_selector, max_attempts=5, wait_time=3, extra_scroll=150):\n",
    "    \"\"\"\n",
    "    Tries to find an element specified by the CSS selector and get its text.\n",
    "    Waits for the element to be visible.\n",
    "    Retries up to max_attempts times if StaleElementReferenceException is encountered.\n",
    "\n",
    "    :param driver: The Selenium WebDriver.\n",
    "    :param css_selector: CSS selector of the element.\n",
    "    :param max_attempts: Maximum number of attempts to try getting the text.\n",
    "    :param wait_time: Time to wait for the element to become visible.\n",
    "    :return: The text of the element if successful, None if it failed after max_attempts.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            # Wait for the element to be visible\n",
    "            element = WebDriverWait(driver, wait_time).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector))\n",
    "            )\n",
    "\n",
    "            # Scroll the element into view with extra space\n",
    "            driver.execute_script(\n",
    "                \"window.scroll(0, arguments[0].getBoundingClientRect().top + window.pageYOffset - arguments[1]);\", \n",
    "                element, extra_scroll)\n",
    "\n",
    "            # Return the text of the element\n",
    "            return element.text\n",
    "\n",
    "        except (StaleElementReferenceException, NoSuchElementException, TimeoutException):\n",
    "            pass\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Selenium Window\n",
    "fun_options = Options()\n",
    "fun_driver = webdriver.Firefox(options=fun_options)\n",
    "fun_driver.get(\"https://www.facebook.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peridot of Earth\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Other_Number</th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Name_First</th>\n",
       "      <th>Name_Last</th>\n",
       "      <th>Gender</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12102965600</td>\n",
       "      <td>596897507</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Murphy</td>\n",
       "      <td>female</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>Married</td>\n",
       "      <td>Stay-at-home mom</td>\n",
       "      <td>12/5/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12102965601</td>\n",
       "      <td>100028359581007</td>\n",
       "      <td>Victor</td>\n",
       "      <td>Ortiz</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/1/0001 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12102965607</td>\n",
       "      <td>1456394131</td>\n",
       "      <td>Alida</td>\n",
       "      <td>Canion</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USAA</td>\n",
       "      <td>12/7/2015 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12102965613</td>\n",
       "      <td>100016005185942</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Duerr</td>\n",
       "      <td>male</td>\n",
       "      <td>Somerset, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAA</td>\n",
       "      <td>11/29/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12102965614</td>\n",
       "      <td>100009325868432</td>\n",
       "      <td>George</td>\n",
       "      <td>Gomez</td>\n",
       "      <td>male</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>San Antonio, Texas</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/19/2018 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Other_Number          Url_Key Name_First Name_Last  Gender  \\\n",
       "0  12102965600        596897507      Sarah    Murphy  female   \n",
       "1  12102965601  100028359581007     Victor     Ortiz    male   \n",
       "2  12102965607       1456394131      Alida    Canion  female   \n",
       "3  12102965613  100016005185942     Austin     Duerr    male   \n",
       "4  12102965614  100009325868432     George     Gomez    male   \n",
       "\n",
       "                    1                   2        3                 4  \\\n",
       "0  San Antonio, Texas  San Antonio, Texas  Married  Stay-at-home mom   \n",
       "1                 NaN                 NaN      NaN               NaN   \n",
       "2                 NaN                 NaN      NaN              USAA   \n",
       "3     Somerset, Texas  San Antonio, Texas      NaN               AAA   \n",
       "4  San Antonio, Texas  San Antonio, Texas   Single               NaN   \n",
       "\n",
       "               5    6      7    8    9  \n",
       "0   12/5/2018 12  0.0  00 AM  NaN  NaN  \n",
       "1    1/1/0001 12  0.0  00 AM  NaN  NaN  \n",
       "2   12/7/2015 12  0.0  00 AM  NaN  NaN  \n",
       "3  11/29/2018 12  0.0  00 AM  NaN  NaN  \n",
       "4  11/19/2018 12  0.0  00 AM  NaN  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_csv(\"../Webscrape_Data/sample_edited.txt\", sep=\":\", header=None, \n",
    "                        names=[\"Other_Number\", \"Url_Key\", \"Name_First\", \"Name_Last\", \"Gender\",\n",
    "                               \"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])\n",
    "df_sample['Url_Key'] = df_sample['Url_Key'].astype(str)\n",
    "\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>...</th>\n",
       "      <th>Details About Matthew</th>\n",
       "      <th>Details About Frederick</th>\n",
       "      <th>Details About Julianna</th>\n",
       "      <th>Details About Cordell</th>\n",
       "      <th>Details About Richard</th>\n",
       "      <th>Details About Mary</th>\n",
       "      <th>Details About Natalie</th>\n",
       "      <th>Details About Lamberto</th>\n",
       "      <th>Details About Tim</th>\n",
       "      <th>Details About Jerry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>100001408108204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scraper 0 has dibs!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>100001408108204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrape Failed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>100008340486824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scraper 0 has dibs!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>100008340486824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scrape Failed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>100001924928893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scraper 0 has dibs!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Url_Key Profile Picture Link                 Name  Num_Friends  \\\n",
       "517  100001408108204                  NaN  Scraper 0 has dibs!          NaN   \n",
       "518  100001408108204                  NaN        Scrape Failed          NaN   \n",
       "519  100008340486824                  NaN  Scraper 0 has dibs!          NaN   \n",
       "520  100008340486824                  NaN        Scrape Failed          NaN   \n",
       "521  100001924928893                  NaN  Scraper 0 has dibs!          NaN   \n",
       "\n",
       "    Intro 1 Intro 2 Intro 3 Intro 4 Intro 5 Overview (About)  ...  \\\n",
       "517     NaN     NaN     NaN     NaN     NaN              NaN  ...   \n",
       "518     NaN     NaN     NaN     NaN     NaN              NaN  ...   \n",
       "519     NaN     NaN     NaN     NaN     NaN              NaN  ...   \n",
       "520     NaN     NaN     NaN     NaN     NaN              NaN  ...   \n",
       "521     NaN     NaN     NaN     NaN     NaN              NaN  ...   \n",
       "\n",
       "    Details About Matthew Details About Frederick Details About Julianna  \\\n",
       "517                   NaN                     NaN                    NaN   \n",
       "518                   NaN                     NaN                    NaN   \n",
       "519                   NaN                     NaN                    NaN   \n",
       "520                   NaN                     NaN                    NaN   \n",
       "521                   NaN                     NaN                    NaN   \n",
       "\n",
       "    Details About Cordell Details About Richard Details About Mary  \\\n",
       "517                   NaN                   NaN                NaN   \n",
       "518                   NaN                   NaN                NaN   \n",
       "519                   NaN                   NaN                NaN   \n",
       "520                   NaN                   NaN                NaN   \n",
       "521                   NaN                   NaN                NaN   \n",
       "\n",
       "    Details About Natalie Details About Lamberto Details About Tim  \\\n",
       "517                   NaN                    NaN               NaN   \n",
       "518                   NaN                    NaN               NaN   \n",
       "519                   NaN                    NaN               NaN   \n",
       "520                   NaN                    NaN               NaN   \n",
       "521                   NaN                    NaN               NaN   \n",
       "\n",
       "    Details About Jerry  \n",
       "517                 NaN  \n",
       "518                 NaN  \n",
       "519                 NaN  \n",
       "520                 NaN  \n",
       "521                 NaN  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped = pd.read_csv(\"../Webscrape_Data/scraped_data.csv\")\n",
    "df_scraped.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 72)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL key 100014245629916 already exists in df_scraped, skipping data gathering.\n",
      "URL key 601284842 already exists in df_scraped, skipping data gathering.\n",
      "URL key 1619636620 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100015881253192 already exists in df_scraped, skipping data gathering.\n",
      "URL key 100006578763063 already exists in df_scraped, skipping data gathering.\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: Failed to decode response from marionette\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2314b4cf174e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mfun_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.facebook.com/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mUrl_Key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Gather data using Url_Key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mdict_person\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Url_Key\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mUrl_Key\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;34m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"url\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: Failed to decode response from marionette\n"
     ]
    }
   ],
   "source": [
    "df_sample = df_sample.iloc[(df_scraped.shape[0] - 10):]\n",
    "\n",
    "for Url_Key in df_sample['Url_Key']:\n",
    "    sleep(0.5 + randint(10,9999999)/10000000)\n",
    "    # Check if Url_Key is not in df_scraped\n",
    "    df_scraped = pd.read_csv(\"../Webscrape_Data/scraped_data.csv\", error_bad_lines=False)\n",
    "    df_scraped['Url_Key'] = df_scraped['Url_Key'].astype(str)\n",
    "    Url_Key = str(Url_Key)\n",
    "    if Url_Key not in df_scraped['Url_Key'].values:\n",
    "        \n",
    "        # Calling Dibs on this profile\n",
    "        dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scraper 0 has dibs!\"}\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"../Webscrape_Data/scraped_data.csv\", index = False)\n",
    "        \n",
    "        \n",
    "        fun_driver.get(\"https://www.facebook.com/\" + Url_Key)\n",
    "        # Gather data using Url_Key\n",
    "        dict_person = {\"Url_Key\" : Url_Key}\n",
    "        try:\n",
    "            # Obtain Profile Picture\n",
    "            dict_person[\"Profile Picture Link\"] = fun_driver.find_element(by=\"css selector\", \n",
    "                value = \"a.xzsf02u > div:nth-child(1) > svg:nth-child(1) > g:nth-child(2) > image:nth-child(1)\"\n",
    "                ).get_attribute(\"xlink:href\")\n",
    "\n",
    "            # Obtain Name\n",
    "            dict_person[\"Name\"] = get_text_with_retry(fun_driver, \".x14qwyeo > h1:nth-child(1)\")\n",
    "\n",
    "            # Obtain Number of Friends\n",
    "            dict_person[\"Num_Friends\"] = int(get_text_with_retry(fun_driver, \"a.xi81zsa\").split(\" \")[0])\n",
    "\n",
    "            # Obtain Intro Lines\n",
    "            html_current = BeautifulSoup(fun_driver.page_source, \"lxml\")\n",
    "            list_intro_el = html_current.select(\n",
    "                \"div.x7wzq59:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "                + \" div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "                + \" ul:nth-child(1) > div\")\n",
    "            for num in range(len(list_intro_el)):\n",
    "                dict_person[\"Intro \" + str(num + 1)] = list_intro_el[num].text\n",
    "                #print(list_intro_el[num].text)\n",
    "\n",
    "\n",
    "            # Click About Tab\n",
    "            click_with_retry(fun_driver, \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\")\n",
    "            #Get Overview Section First\n",
    "            dict_person[\"Overview (About)\"] = get_text_with_retry(fun_driver, \".xqmdsaz\")\n",
    "            \n",
    "            # Obtain About Section\n",
    "            for num in range(3, 9):\n",
    "                css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "                click_with_retry(fun_driver, css_selector_to_click)\n",
    "                el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "                el_temp_text = el_temp.text\n",
    "                css_path_content = \".xqmdsaz\"\n",
    "                content_text = get_text_with_retry(fun_driver, css_path_content)\n",
    "                if content_text is not None:\n",
    "                    dict_person[el_temp_text] = content_text\n",
    "                    #print(\"element's text hath been saved!\")\n",
    "                else:\n",
    "                    print(\"Failed to retrieve text for element:\", el_temp_text)\n",
    "        except:\n",
    "            dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scrape Failed\"}\n",
    "        \n",
    "        \n",
    "        # Append the new data to df_scraped\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"../Webscrape_Data/scraped_data.csv\", index = False)\n",
    "    \n",
    "    else:\n",
    "        # Skip the data gathering process\n",
    "        print(f\"URL key {Url_Key} already exists in df_scraped, skipping data gathering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Test Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Url_Key = \"596897507\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_driver.get(\"https://www.facebook.com/\" + Url_Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_person = {}\n",
    "# Need to obtain the following:\n",
    "# Profile Picture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_person[\"Url_Key\"] = Url_Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Profile Picture\n",
    "dict_person[\"Profile Picture Link\"] = fun_driver.find_element(by=\"css selector\", \n",
    "    value = \"a.xzsf02u > div:nth-child(1) > svg:nth-child(1) > g:nth-child(2) > image:nth-child(1)\"\n",
    "    ).get_attribute(\"xlink:href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Name\n",
    "dict_person[\"Name\"] = get_text_with_retry(fun_driver, \".x14qwyeo > h1:nth-child(1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Number of Friends\n",
    "dict_person[\"Num_Friends\"] = int(get_text_with_retry(fun_driver, \"a.xi81zsa\").split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went to Ashland High School\n",
      "Lives in San Antonio, Texas\n",
      "From San Antonio, Texas\n",
      "Married to Matt Murphy\n",
      "Joined October 2007\n"
     ]
    }
   ],
   "source": [
    "# Obtain Intro Lines\n",
    "html_current = BeautifulSoup(fun_driver.page_source, \"lxml\")\n",
    "\n",
    "list_intro_el = html_current.select(\n",
    "    \"div.x7wzq59:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "    + \" div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > div:nth-child(1) > div:nth-child(1) >\"\n",
    "    + \" ul:nth-child(1) > div\")\n",
    "\n",
    "for num in range(len(list_intro_el)):\n",
    "    dict_person[\"Intro \" + str(num + 1)] = list_intro_el[num].text\n",
    "    print(list_intro_el[num].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click About Tab\n",
    "click_with_retry(fun_driver, \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\")\n",
    "\n",
    "#Get Overview Section First\n",
    "dict_person[\"Overview (About)\"] = get_text_with_retry(fun_driver, \".xqmdsaz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "temp el: Work and education clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Places lived clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Contact and basic info clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Family and relationships clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Details About Sarah clicked\n",
      "element's text hath been saved!\n",
      "---------------------------------\n",
      "temp el: Life events clicked\n",
      "element's text hath been saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtain About Section\n",
    "for num in range(3, 9):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # CSS selector for the current element to click\n",
    "    css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    \n",
    "    # Clicking the next About Sub-Section\n",
    "    click_with_retry(fun_driver, css_selector_to_click)\n",
    "    \n",
    "    # Re-find the element to avoid stale reference\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "    el_temp_text = el_temp.text\n",
    "    print(\"temp el: \" + el_temp_text + \" clicked\")\n",
    "    \n",
    "    # Consuming its informational content\n",
    "    css_path_content = \".xqmdsaz\"\n",
    "    content_text = get_text_with_retry(fun_driver, css_path_content)\n",
    "    if content_text is not None:\n",
    "        dict_person[el_temp_text] = content_text\n",
    "        print(\"element's text hath been saved!\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve text for element:\", el_temp_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>Work and education</th>\n",
       "      <th>Places lived</th>\n",
       "      <th>Contact and basic info</th>\n",
       "      <th>Family and relationships</th>\n",
       "      <th>Details About Sarah</th>\n",
       "      <th>Life events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596897507</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...</td>\n",
       "      <td>Sarah Murphy</td>\n",
       "      <td>444</td>\n",
       "      <td>Went to Ashland High School</td>\n",
       "      <td>Lives in San Antonio, Texas</td>\n",
       "      <td>From San Antonio, Texas</td>\n",
       "      <td>Married to Matt Murphy</td>\n",
       "      <td>Joined October 2007</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>Work\\nNo workplaces to show\\nCollege\\nNo schoo...</td>\n",
       "      <td>Places lived\\nSan Antonio, Texas\\nCurrent city...</td>\n",
       "      <td>Contact info\\nNo contact info to show\\nWebsite...</td>\n",
       "      <td>Relationship\\nMatt Murphy\\nMarried to Matt Mur...</td>\n",
       "      <td>2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Url_Key                               Profile Picture Link  \\\n",
       "0  596897507  https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...   \n",
       "\n",
       "            Name  Num_Friends                      Intro 1  \\\n",
       "0  Sarah Murphy           444  Went to Ashland High School   \n",
       "\n",
       "                       Intro 2                  Intro 3  \\\n",
       "0  Lives in San Antonio, Texas  From San Antonio, Texas   \n",
       "\n",
       "                  Intro 4              Intro 5  \\\n",
       "0  Married to Matt Murphy  Joined October 2007   \n",
       "\n",
       "                                    Overview (About)  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                  Work and education  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                        Places lived  \\\n",
       "0  Work\\nNo workplaces to show\\nCollege\\nNo schoo...   \n",
       "\n",
       "                              Contact and basic info  \\\n",
       "0  Places lived\\nSan Antonio, Texas\\nCurrent city...   \n",
       "\n",
       "                            Family and relationships  \\\n",
       "0  Contact info\\nNo contact info to show\\nWebsite...   \n",
       "\n",
       "                                 Details About Sarah  \\\n",
       "0  Relationship\\nMatt Murphy\\nMarried to Matt Mur...   \n",
       "\n",
       "                                         Life events  \n",
       "0  2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scraped = pd.DataFrame(dict_person, index=[0])\n",
    "df_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraped.to_csv(\"../Webscrape_Data/scraped_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url_Key</th>\n",
       "      <th>Profile Picture Link</th>\n",
       "      <th>Name</th>\n",
       "      <th>Num_Friends</th>\n",
       "      <th>Intro 1</th>\n",
       "      <th>Intro 2</th>\n",
       "      <th>Intro 3</th>\n",
       "      <th>Intro 4</th>\n",
       "      <th>Intro 5</th>\n",
       "      <th>Overview (About)</th>\n",
       "      <th>Work and education</th>\n",
       "      <th>Places lived</th>\n",
       "      <th>Contact and basic info</th>\n",
       "      <th>Family and relationships</th>\n",
       "      <th>Details About Sarah</th>\n",
       "      <th>Life events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596897507</td>\n",
       "      <td>https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...</td>\n",
       "      <td>Sarah Murphy</td>\n",
       "      <td>444</td>\n",
       "      <td>Went to Ashland High School</td>\n",
       "      <td>Lives in San Antonio, Texas</td>\n",
       "      <td>From San Antonio, Texas</td>\n",
       "      <td>Married to Matt Murphy</td>\n",
       "      <td>Joined October 2007</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>No workplaces to show\\nWent to Ashland High Sc...</td>\n",
       "      <td>Work\\nNo workplaces to show\\nCollege\\nNo schoo...</td>\n",
       "      <td>Places lived\\nSan Antonio, Texas\\nCurrent city...</td>\n",
       "      <td>Contact info\\nNo contact info to show\\nWebsite...</td>\n",
       "      <td>Relationship\\nMatt Murphy\\nMarried to Matt Mur...</td>\n",
       "      <td>2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Url_Key                               Profile Picture Link  \\\n",
       "0  596897507  https://scontent-sjc3-1.xx.fbcdn.net/v/t39.308...   \n",
       "\n",
       "            Name  Num_Friends                      Intro 1  \\\n",
       "0  Sarah Murphy           444  Went to Ashland High School   \n",
       "\n",
       "                       Intro 2                  Intro 3  \\\n",
       "0  Lives in San Antonio, Texas  From San Antonio, Texas   \n",
       "\n",
       "                  Intro 4              Intro 5  \\\n",
       "0  Married to Matt Murphy  Joined October 2007   \n",
       "\n",
       "                                    Overview (About)  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                  Work and education  \\\n",
       "0  No workplaces to show\\nWent to Ashland High Sc...   \n",
       "\n",
       "                                        Places lived  \\\n",
       "0  Work\\nNo workplaces to show\\nCollege\\nNo schoo...   \n",
       "\n",
       "                              Contact and basic info  \\\n",
       "0  Places lived\\nSan Antonio, Texas\\nCurrent city...   \n",
       "\n",
       "                            Family and relationships  \\\n",
       "0  Contact info\\nNo contact info to show\\nWebsite...   \n",
       "\n",
       "                                 Details About Sarah  \\\n",
       "0  Relationship\\nMatt Murphy\\nMarried to Matt Mur...   \n",
       "\n",
       "                                         Life events  \n",
       "0  2017\\nMarried Matt Murphy\\n2011\\nMatt Murphy a...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../Webscrape_Data/scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fun_extended_wait(css_selector, driver):\n",
    "    locator = (By.CSS_SELECTOR, css_selector)\n",
    "    try:\n",
    "        # Wait for the element to be available and interact with it\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))\n",
    "        # Perform actions with element\n",
    "    except StaleElementReferenceException:\n",
    "        # Element is stale, re-find or handle the exception\n",
    "        element = WebDriverWait(driver, 10).until(EC.presence_of_element_located(locator))\n",
    "        # Perform actions with refreshed element\n",
    "    sleep(1 + randint(10,9999999)/10000000)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for num in range(3,8):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # Clicking next About Sub-Section\n",
    "    css_path = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    fun_extended_wait(css_path, fun_driver)\n",
    "    sleep(3 + randint(10,9999999)/10000000)\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value = css_path)\n",
    "    el_temp.click()\n",
    "    print(\"temp el: \" + el_temp.text + \" clicked\")\n",
    "    \n",
    "    # Consuming it's informational meat\n",
    "    css_path = \".xqmdsaz\"\n",
    "    fun_extended_wait(css_path, fun_driver)\n",
    "    dict_person[el_temp.text] = fun_driver.find_element(by=\"css selector\", value = css_path).text\n",
    "    print(\"element's text hath been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path)\n",
    "\n",
    "def open_browser(alt_user_name = 'Thank you for your website'):\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=\" + str(alt_user_name))\n",
    "    path = '../Garage/chromedriver'         # Path to Chromedriver\n",
    "    return webdriver.Chrome(executable_path = path, options=opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for num in range(3,8):\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "    # CSS selector for the current element to click\n",
    "    css_selector_to_click = \".x16jcvb6 > div:nth-child(\" + str(num) + \") > a:nth-child(1)\"\n",
    "    \n",
    "    # Clicking the next About Sub-Section\n",
    "    click_with_retry(fun_driver, css_selector_to_click)\n",
    "    \n",
    "    # Re-find the element to avoid stale reference\n",
    "    el_temp = fun_driver.find_element(by=\"css selector\", value=css_selector_to_click)\n",
    "    print(\"temp el: \" + el_temp.text + \" clicked\")\n",
    "    \n",
    "    # Consuming it's informational meat\n",
    "    css_path = \".xqmdsaz\"\n",
    "    #fun_extended_wait(css_path, fun_driver)\n",
    "    dict_person[el_temp.text] = fun_driver.find_element(by=\"css selector\", value = css_path).text\n",
    "    print(\"element's text hath been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\",\n",
    "                        value = \"a.x1i10hfl:nth-child(3) > div:nth-child(1) > span:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_overview = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Overview (About)\"] = about_overview\n",
    "about_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #2 Work & Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(3) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_workanded = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Work & Education (About)\"] = about_workanded\n",
    "about_workanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #3 Places Lived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(4) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_placeslived = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Places Lived (About)\"] = about_placeslived\n",
    "about_placeslived\n",
    "# Should be placed into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #4 Contact and basic info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(5) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_contact = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Contact and basic info (About)\"] = about_contact\n",
    "about_contact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #5 Family and Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(6) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_family = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Family & Relationships (About)\"] = about_family\n",
    "about_family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #6 Details About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(7) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_details = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Details About Profile (About)\"] = about_details\n",
    "about_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### #7 Life Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun_driver.find_element(by=\"css selector\", value = \".x16jcvb6 > div:nth-child(8) > a:nth-child(1)\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_overview = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Overview (About)\"] = about_overview\n",
    "about_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Calling Dibs on this profile\n",
    "        dict_person = {\"Url_Key\": Url_Key, \"Name\" : \"Scraper # has dibs!\"}\n",
    "        df_scraped = pd.concat([df_scraped, \n",
    "            pd.DataFrame(dict_person, index=[0])], ignore_index=True)\n",
    "        df_scraped.to_csv(\"../Webscrape_Data/scraped_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about_lifeEvents = fun_driver.find_element(by=\"css selector\", value = \".xqmdsaz\").text\n",
    "dict_person[\"Life Events (About)\"] = about_lifeEvents\n",
    "about_lifeEvents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
